{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intent LLM Playground\n",
        "\n",
        "Use this notebook to exercise the intents classifier + slot filler end to end. Configure your Ollama endpoint, type some artifact text, and capture the raw responses before wiring them into the worker.\n",
        "\n",
        "> Tip: keep Ollama running (`ollama serve`) and ensure the requested model is already pulled. You can also swap in a mock responder if you want deterministic outputs (see the optional section below).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "postgresql://postgres:postgres@localhost:5432/haven\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "INTENT_MODEL = os.getenv(\"INTENT_MODEL\", \"llama3.2:latest\")\n",
        "DOCUMENT_ID = \"775ecfe1-7508-44af-95a0-3029b8f7fc97\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Database connection setup\n",
        "# ---------------------------------------------------------------------------\n",
        "# Override DATABASE_URL to use localhost when running locally (outside Docker)\n",
        "# The default connection string uses 'postgres' hostname which only works inside Docker\n",
        "if \"DATABASE_URL\" not in os.environ:\n",
        "    # Default to localhost for local development\n",
        "    os.environ[\"DATABASE_URL\"] = \"postgresql://postgres:postgres@localhost:5432/haven\"\n",
        "elif \"@postgres:\" in os.environ.get(\"DATABASE_URL\", \"\"):\n",
        "    # If DATABASE_URL uses 'postgres' hostname, replace with 'localhost' for local notebook usage\n",
        "    os.environ[\"DATABASE_URL\"] = os.environ[\"DATABASE_URL\"].replace(\"@postgres:\", \"@localhost:\")\n",
        "\n",
        "DATABASE_URL = os.environ[\"DATABASE_URL\"]\n",
        "print(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/chrispatten/workspace/haven\n",
            "Using Ollama endpoint: http://localhost:11434\n",
            "Model: llama3.2:latest\n",
            "Taxonomy: /Users/chrispatten/workspace/haven/services/worker_service/taxonomies/taxonomy_v1.0.0.yaml\n",
            "Database: postgresql://postgres:postgres@localhost:5432/haven\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "from uuid import uuid4\n",
        "\n",
        "import httpx\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Ensure the Haven project root (and src/) are importable before using modules\n",
        "# ---------------------------------------------------------------------------\n",
        "def resolve_project_root() -> Path:\n",
        "    env_root = Path(os.getenv(\"HAVEN_PROJECT_ROOT\", \"\")).expanduser()\n",
        "    if env_root and (env_root / \"src\" / \"haven\").exists():\n",
        "        return env_root\n",
        "\n",
        "    cwd = Path.cwd().resolve()\n",
        "    if (cwd / \"src\" / \"haven\").exists():\n",
        "        return cwd\n",
        "\n",
        "    if (cwd.parent / \"src\" / \"haven\").exists():\n",
        "        return cwd.parent\n",
        "\n",
        "    raise RuntimeError(\n",
        "        \"Unable to locate Haven project root. Set HAVEN_PROJECT_ROOT or launch the notebook from the repo root.\"\n",
        "    )\n",
        "\n",
        "\n",
        "PROJECT_ROOT = resolve_project_root()\n",
        "SRC_PATH = PROJECT_ROOT / \"src\"\n",
        "for candidate in (PROJECT_ROOT, SRC_PATH):\n",
        "    path_str = str(candidate)\n",
        "    if path_str not in sys.path:\n",
        "        sys.path.insert(0, path_str)\n",
        "\n",
        "from haven.intents.classifier.classifier import ClassifierSettings, classify_artifact\n",
        "from haven.intents.classifier.taxonomy import IntentTaxonomy, load_taxonomy\n",
        "from haven.intents.models import ClassificationResult\n",
        "from haven.intents.slots import SlotFiller, SlotFillerResult, SlotFillerSettings\n",
        "from haven.intents.utils import resolve_sender_name\n",
        "from shared.logging import setup_logging\n",
        "from shared.db import get_connection\n",
        "from shared.models_v2 import Document\n",
        "from shared.context_utilities import format_context, get_context_by_document_id\n",
        "from uuid import UUID\n",
        "import psycopg\n",
        "from psycopg.rows import dict_row\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Configure runtime knobs here\n",
        "# ---------------------------------------------------------------------------\n",
        "OLLAMA_BASE_URL = 'http://localhost:11434' # os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "DEFAULT_TAXONOMY_PATH = PROJECT_ROOT / \"services/worker_service/taxonomies/taxonomy_v1.0.0.yaml\"\n",
        "\n",
        "# Optional: point to an alternate taxonomy payload if you're testing new definitions\n",
        "CUSTOM_TAXONOMY_PATH = os.getenv(\"INTENT_TAXONOMY_PATH\")\n",
        "\n",
        "from shared.db import get_conn_str\n",
        "\n",
        "setup_logging()\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Using Ollama endpoint: {OLLAMA_BASE_URL}\")\n",
        "print(f\"Model: {INTENT_MODEL}\")\n",
        "print(f\"Taxonomy: {CUSTOM_TAXONOMY_PATH or DEFAULT_TAXONOMY_PATH}\")\n",
        "print(f\"Database: {DATABASE_URL}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Message:\n",
            "Chris Patten at 2025-11-05T18:05Z - ve got a work thing at Clarys just down the street so I can come grab you and if we have time to kill before the next train we can go back there\n",
            "\n",
            "Previous Messages:\n",
            "Chris Patten at 2025-11-05T18:04Z - \"__kIMFileTransferGUIDAttributeName)at_0_B2C2CECB-7753-4BDE-968B-35590F83BD6E__kIMMessagePartAttributeNameNSNumber\n",
            "Chris Patten at 2025-11-05T18:03Z - Dartmouth Street. The bus is super easy, you go past baggage claim and theres TONS of signs for the different busses. This one stops at the Logan express area curbside and is orange with a big BACK BAY painted on it\n",
            "Stephanie Patten at 2025-11-05T18:02Z - ï¿¼Which location do I get off at if I can even find the bus at the airport\n",
            "Chris Patten at 2025-11-05T12:07Z - \u00011\u00016\u0001;\u0001F\u0001H\u0001J\u0001L\u0001]\u0001_\u0001a\u0001c\u0001e\u0001g\u0001i\u0001k\u0001t\u0001v\u0001x\u0001z\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\u0001ï¿½\n",
            "Chris Patten at 2025-11-05T12:07Z - https://www.massport.com/logan-airport/getting-to-logan/logan-express/back-bay\n",
            "\n",
            "\n",
            "Detected Entities:\n",
            "Clarys - person\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = get_context_by_document_id(DOCUMENT_ID)\n",
        "print(format_context(context))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_database_connection() -> bool:\n",
        "    \"\"\"Test database connection and print helpful diagnostics.\"\"\"\n",
        "    try:\n",
        "        print(f\"Testing database connection...\")\n",
        "        \n",
        "        with get_connection() as conn:\n",
        "            with conn.cursor() as cur:\n",
        "                cur.execute(\"SELECT version();\")\n",
        "                version = cur.fetchone()[0]\n",
        "                print(f\"âœ“ Database connection successful!\")\n",
        "                print(f\"  PostgreSQL version: {version.split(',')[0]}\")\n",
        "                return True\n",
        "    except psycopg.OperationalError as exc:\n",
        "        print(f\"âœ— Database connection failed: {exc}\")\n",
        "        print(f\"\\nTroubleshooting:\")\n",
        "        print(f\"  1. Check if database is running: docker compose ps\")\n",
        "        print(f\"  2. Start database if needed: docker compose up -d postgres\")\n",
        "        print(f\"  3. Verify DATABASE_URL environment variable\")\n",
        "        print(f\"  4. For Docker: ensure host is 'localhost' (not 'postgres')\")\n",
        "        return False\n",
        "    except Exception as exc:\n",
        "        print(f\"âœ— Unexpected error: {exc}\")\n",
        "        print(f\"  Error type: {type(exc).__name__}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def load_intent_taxonomy(path: Optional[Path] = None) -> IntentTaxonomy:\n",
        "    resolved = Path(path or CUSTOM_TAXONOMY_PATH or DEFAULT_TAXONOMY_PATH).expanduser()\n",
        "    if not resolved.exists():\n",
        "        raise FileNotFoundError(f\"Taxonomy file not found: {resolved}\")\n",
        "    return load_taxonomy(resolved)\n",
        "\n",
        "\n",
        "def build_slot_filler() -> SlotFiller:\n",
        "    return SlotFiller(\n",
        "        SlotFillerSettings(\n",
        "            ollama_base_url=OLLAMA_BASE_URL,\n",
        "            slot_model=INTENT_MODEL,\n",
        "            request_timeout=30.0,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def fetch_document_by_id(doc_id: Union[str, UUID]) -> Optional[Document]:\n",
        "    \"\"\"Fetch a document by its doc_id from the database.\"\"\"\n",
        "    try:\n",
        "        doc_uuid = UUID(str(doc_id))\n",
        "    except ValueError as exc:\n",
        "        print(f\"Invalid document ID format: {doc_id}\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        with get_connection() as conn:\n",
        "            with conn.cursor(row_factory=dict_row) as cur:\n",
        "                cur.execute(\n",
        "                    \"\"\"\n",
        "                    SELECT *\n",
        "                    FROM documents\n",
        "                    WHERE doc_id = %s\n",
        "                    ORDER BY is_active_version DESC, version_number DESC\n",
        "                    LIMIT 1\n",
        "                    \"\"\",\n",
        "                    (doc_uuid,),\n",
        "                )\n",
        "                row = cur.fetchone()\n",
        "                if not row:\n",
        "                    print(f\"Document not found in database: {doc_id}\")\n",
        "                    return None\n",
        "                return Document(**row)\n",
        "    except psycopg.OperationalError as exc:\n",
        "        print(f\"Database connection error: {exc}\")\n",
        "        print(f\"Current DATABASE_URL: {DATABASE_URL}\")\n",
        "        print(\"\\nTip: Make sure:\")\n",
        "        print(\"  1. Database is running (check with: docker compose ps)\")\n",
        "        print(\"  2. DATABASE_URL environment variable is set correctly\")\n",
        "        print(\"  3. For Docker: use 'localhost' as host\")\n",
        "        print(\"  4. For local Postgres: ensure host/port/credentials are correct\")\n",
        "        return None\n",
        "    except Exception as exc:\n",
        "        print(f\"Error fetching document: {exc}\")\n",
        "        print(f\"Error type: {type(exc).__name__}\")\n",
        "        return None\n",
        "\n",
        "def get_sender_name(doc: Document) -> Optional[str]:\n",
        "    \"\"\"Resolve the sender name for a document.\n",
        "    \n",
        "    If the document has a people entity with a sender role, use that.\n",
        "    Otherwise, try to resolve the sender from the identifier in the document metadata.\n",
        "    \"\"\"\n",
        "    people = doc.people or []\n",
        "    if people:\n",
        "        print(f\"People: {people}\")\n",
        "        for person in people:\n",
        "            if person.get(\"role\") == \"sender\":\n",
        "                print(f\"Sender: {person}\")\n",
        "                return resolve_sender_name(person.get(\"identifier\"), DATABASE_URL)\n",
        "    return None\n",
        "    \n",
        "    \n",
        "\n",
        "def fetch_thread_context(doc_id: UUID, limit: int = 5) -> Optional[List[Dict[str, Any]]]:\n",
        "    \"\"\"Fetch recent messages from the same thread for conversational context.\n",
        "    \n",
        "    Returns up to `limit` previous messages from the thread, ordered by timestamp.\n",
        "    Each message includes text, sender (with resolved person names), and timestamp for pronoun resolution.\n",
        "    \n",
        "    This is a wrapper around the shared utility function from haven.intents.utils.\n",
        "    \"\"\"\n",
        "    from haven.intents.utils import fetch_thread_context as _fetch_thread_context\n",
        "    import os\n",
        "    \n",
        "    database_url = os.getenv(\"DATABASE_URL\", \"postgresql://postgres:postgres@localhost:5432/haven\")\n",
        "    \n",
        "    try:\n",
        "        return _fetch_thread_context(\n",
        "            database_url=database_url,\n",
        "            doc_id=doc_id,\n",
        "            limit=limit,\n",
        "            time_window_hours=8,  # Match notebook's original behavior\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        print(f\"Warning: Failed to fetch thread context: {exc}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_self_person_id() -> Optional[UUID]:\n",
        "    \"\"\"Fetch the self_person_id from system_settings using shared function.\"\"\"\n",
        "    try:\n",
        "        from shared.people_repository import get_self_person_id_from_settings\n",
        "        with get_connection() as conn:\n",
        "            return get_self_person_id_from_settings(conn)\n",
        "    except Exception as exc:\n",
        "        print(f\"Warning: Failed to fetch self_person_id: {exc}\")\n",
        "        return None\n",
        "\n",
        "def run_intent_pipeline(\n",
        "    *,\n",
        "    text: str,\n",
        "    entities: Dict[str, Any],\n",
        "    source_type: str = \"imessage\",\n",
        "    artifact_id: Optional[str] = None,\n",
        "    client: Optional[httpx.Client] = None,\n",
        "    slot_filler: Optional[SlotFiller] = None,\n",
        "    taxonomy: Optional[IntentTaxonomy] = None,\n",
        "    thread_context: Optional[List[Dict[str, Any]]] = None,\n",
        "    content_timestamp: Optional[str] = None,\n",
        ") -> tuple[ClassificationResult, SlotFillerResult]:\n",
        "    taxonomy = taxonomy or load_intent_taxonomy()\n",
        "    artifact_id = artifact_id or str(uuid4())\n",
        "    owns_client = client is None\n",
        "\n",
        "    if client is None:\n",
        "        client = httpx.Client(base_url=OLLAMA_BASE_URL, timeout=30.0)\n",
        "    if slot_filler is None:\n",
        "        slot_filler = build_slot_filler()\n",
        "\n",
        "    classifier_settings = ClassifierSettings(\n",
        "        base_url=OLLAMA_BASE_URL,\n",
        "        model=INTENT_MODEL,\n",
        "        timeout=30.0,\n",
        "        min_confidence=0.35,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        classification = classify_artifact(\n",
        "            text=text,\n",
        "            taxonomy=taxonomy,\n",
        "            entities=entities,\n",
        "            settings=classifier_settings,\n",
        "            client=client,\n",
        "            thread_context=thread_context,\n",
        "        )\n",
        "        slot_result = slot_filler.fill_slots(\n",
        "            job_text=text,\n",
        "            classification=classification,\n",
        "            taxonomy=taxonomy,\n",
        "            entity_payload=entities,\n",
        "            artifact_id=artifact_id,\n",
        "            source_type=source_type,\n",
        "            thread_context=thread_context,\n",
        "            content_timestamp=content_timestamp,\n",
        "        )\n",
        "    finally:\n",
        "        if owns_client:\n",
        "            client.close()\n",
        "\n",
        "    return classification, slot_result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "postgresql://postgres:postgres@localhost:5432/haven\n",
            "Testing database connection...\n",
            "âœ“ Database connection successful!\n",
            "  PostgreSQL version: PostgreSQL 15.14 (Debian 15.14-1.pgdg12+1) on aarch64-unknown-linux-gnu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(DATABASE_URL)\n",
        "\n",
        "test_database_connection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample artifact + entities\n",
        "\n",
        "Adjust the text/entities below to mirror the document you want to test. Including `channel_context.from` / `channel_context.to` helps the model resolve pronouns for messaging/email content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hey Chris â€” can you remember to grab dog food for me before tomorrow night? \n",
            "I'll be tied up with meetings until late Wednesday.\n",
            "{\n",
            "  \"people\": [\n",
            "    {\n",
            "      \"normalizedValue\": \"Chris\",\n",
            "      \"identifier\": \"imessage:+15551234567\",\n",
            "      \"role\": \"recipient\"\n",
            "    }\n",
            "  ],\n",
            "  \"dates\": [\n",
            "    {\n",
            "      \"normalizedValue\": \"2025-11-12T21:00:00-05:00\",\n",
            "      \"entity\": {\n",
            "        \"text\": \"tomorrow night\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"channel_context\": {\n",
            "    \"from\": {\n",
            "      \"display_name\": \"Alex\",\n",
            "      \"identifier\": \"imessage:+15550987654\"\n",
            "    },\n",
            "    \"to\": [\n",
            "      {\n",
            "        \"display_name\": \"Chris\",\n",
            "        \"identifier\": \"imessage:+15551234567\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"\"\"\n",
        "Hey Chris â€” can you remember to grab dog food for me before tomorrow night? \n",
        "I'll be tied up with meetings until late Wednesday.\n",
        "\"\"\".strip()\n",
        "\n",
        "sample_entities = {\n",
        "    \"people\": [\n",
        "        {\n",
        "            \"normalizedValue\": \"Chris\",\n",
        "            \"identifier\": \"imessage:+15551234567\",\n",
        "            \"role\": \"recipient\",\n",
        "        }\n",
        "    ],\n",
        "    \"dates\": [\n",
        "        {\n",
        "            \"normalizedValue\": \"2025-11-12T21:00:00-05:00\",\n",
        "            \"entity\": {\"text\": \"tomorrow night\"},\n",
        "        }\n",
        "    ],\n",
        "    \"channel_context\": {\n",
        "        \"from\": {\n",
        "            \"display_name\": \"Alex\",\n",
        "            \"identifier\": \"imessage:+15550987654\",\n",
        "        },\n",
        "        \"to\": [\n",
        "            {\n",
        "                \"display_name\": \"Chris\",\n",
        "                \"identifier\": \"imessage:+15551234567\",\n",
        "            }\n",
        "        ],\n",
        "    },\n",
        "}\n",
        "\n",
        "print(sample_text)\n",
        "print(json.dumps(sample_entities, indent=2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full pipeline with comprehensive output and debugging\n",
        "from haven.intents.slots.extractor import LLMSlotExtractor, SlotExtractorSettings\n",
        "from haven.intents.slots.filler import SlotFiller, SlotFillerSettings\n",
        "\n",
        "if 1 == 2:\n",
        "    # Run the full pipeline\n",
        "    classification, slot_result = run_intent_pipeline(\n",
        "        text=sample_text,\n",
        "        entities=sample_entities,\n",
        "        source_type=\"imessage\",\n",
        "    )\n",
        "\n",
        "    # Show detailed slot extraction debugging for the first intent (if there are missing slots)\n",
        "    if classification.intents and slot_result.assignments:\n",
        "        taxonomy = load_intent_taxonomy()\n",
        "        top_intent = classification.intents[0]\n",
        "        top_assignment = slot_result.assignments[0]\n",
        "        intent_def = taxonomy.intents.get(top_intent.intent_name)\n",
        "        \n",
        "        if intent_def and top_assignment.missing_slots:\n",
        "            slot_filler = build_slot_filler()\n",
        "            extractor = slot_filler._extractor\n",
        "            \n",
        "            # Build the prompt that would be used for missing slots\n",
        "            prompt = extractor._build_prompt(\n",
        "                intent_name=top_intent.intent_name,\n",
        "                intent_definition=intent_def,\n",
        "                text=sample_text,\n",
        "                entities=sample_entities,\n",
        "                existing_slots=top_assignment.slots,\n",
        "                missing_slots=top_assignment.missing_slots,\n",
        "                classification_notes=classification.processing_notes or [],\n",
        "                thread_context=None,  # Note: thread_context not used in sample cell, but available in doc_id cell\n",
        "            )\n",
        "            \n",
        "            print(\"=\" * 80)\n",
        "            print(\"SLOT EXTRACTION DEBUGGING (for missing slots)\")\n",
        "            print(\"=\" * 80)\n",
        "            print(\"\\nPrompt sent to LLM:\")\n",
        "            print(\"-\" * 80)\n",
        "            print(prompt)\n",
        "            \n",
        "            print(\"\\n\" + \"-\" * 80)\n",
        "            print(\"RAW OLLAMA SLOT EXTRACTION RESPONSE\")\n",
        "            print(\"-\" * 80)\n",
        "            payload = {\n",
        "                \"model\": INTENT_MODEL,\n",
        "                \"prompt\": prompt,\n",
        "                \"format\": \"json\",\n",
        "                \"stream\": False,\n",
        "            }\n",
        "            raw_response = extractor._invoke_ollama(payload)\n",
        "            print(raw_response)\n",
        "            \n",
        "            print(\"\\n\" + \"-\" * 80)\n",
        "            print(\"PARSED SLOT EXTRACTION JSON\")\n",
        "            print(\"-\" * 80)\n",
        "            parsed = extractor._parse_response(raw_response)\n",
        "            print(json.dumps(parsed, indent=2))\n",
        "            \n",
        "            if \"slots\" in parsed:\n",
        "                print(\"\\n\" + \"-\" * 80)\n",
        "                print(\"EXTRACTED SLOTS FROM LLM\")\n",
        "                print(\"-\" * 80)\n",
        "                print(json.dumps(parsed[\"slots\"], indent=2))\n",
        "                for slot_name in top_assignment.missing_slots:\n",
        "                    if slot_name in parsed[\"slots\"]:\n",
        "                        print(f\"\\nâœ“ '{slot_name}' slot found: {repr(parsed['slots'][slot_name])}\")\n",
        "                    else:\n",
        "                        print(f\"\\nâœ— '{slot_name}' slot NOT found in response\")\n",
        "            \n",
        "            if \"notes\" in parsed:\n",
        "                print(\"\\n\" + \"-\" * 80)\n",
        "                print(\"EXTRACTION NOTES FROM LLM\")\n",
        "                print(\"-\" * 80)\n",
        "                for note in parsed[\"notes\"]:\n",
        "                    print(f\"  â€¢ {note}\")\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "    # Show formatted classifier and slot filling output\n",
        "    print(\"CLASSIFIER OUTPUT\")\n",
        "    print(\"=\" * 80)\n",
        "    for intent in classification.intents:\n",
        "        print(f\"\\nâœ“ Intent: {intent.intent_name}\")\n",
        "        print(f\"  Confidence: {intent.confidence:.2%} (base: {intent.base_confidence:.2%}, prior: {intent.prior_applied:.2f}x)\")\n",
        "        if intent.reasons:\n",
        "            print(f\"  Reasons:\")\n",
        "            for reason in intent.reasons:\n",
        "                print(f\"    â€¢ {reason}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SLOT FILLING OUTPUT\")\n",
        "    print(\"=\" * 80)\n",
        "    for assignment in slot_result.assignments:\n",
        "        print(f\"\\nðŸ“‹ Intent: {assignment.intent_name} ({assignment.confidence:.2%})\")\n",
        "        \n",
        "        if assignment.slots:\n",
        "            print(f\"  âœ“ Resolved Slots:\")\n",
        "            for slot_name, value in assignment.slots.items():\n",
        "                source = assignment.slot_sources.get(slot_name, \"?\")\n",
        "                if isinstance(value, (dict, list)):\n",
        "                    print(f\"    â€¢ {slot_name} (from {source}): {json.dumps(value)}\")\n",
        "                else:\n",
        "                    print(f\"    â€¢ {slot_name} (from {source}): {value}\")\n",
        "        \n",
        "        if assignment.missing_slots:\n",
        "            print(f\"  âš  Missing Required Slots: {', '.join(assignment.missing_slots)}\")\n",
        "        \n",
        "        if assignment.notes:\n",
        "            print(f\"  â„¹ Notes:\")\n",
        "            for note in assignment.notes:\n",
        "                print(f\"    â€¢ {note}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Text analyzed: '{sample_text[:60]}...'\")\n",
        "    print(f\"Source type: imessage\")\n",
        "    print(f\"Channel context: from={sample_entities['channel_context']['from']['display_name']}, to={[p['display_name'] for p in sample_entities['channel_context']['to']]}\")\n",
        "    print(f\"Intents detected: {len(classification.intents)}\")\n",
        "    print(f\"Top intent: {classification.intents[0].intent_name if classification.intents else 'none'}\")\n",
        "    if slot_result.assignments:\n",
        "        top_assignment = slot_result.assignments[0]\n",
        "        print(f\"Resolved slots: {len(top_assignment.slots)} / {len(top_assignment.slots) + len(top_assignment.missing_slots)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "fetch_thread_context(doc_id=UUID('4061ec98-f56e-4e05-86ae-4036129631f1'), limit=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROCESSING DOCUMENT: 12c4133d-991d-4afb-8dcc-5076973c0110\n",
            "================================================================================\n",
            "External ID: imessage:4C99B3B9-BA1D-4537-92DB-C59D22A0E3A6\n",
            "Source Type: imessage\n",
            "Thread ID: 4c14bb3a-45ee-4f86-ba53-162549a97265\n",
            "Text preview: Hey if u think of it could you grab me a couple more of those tank things?...\n",
            "People: [{'role': 'sender', 'metadata': {}, 'identifier': 'E:mrwhistler@gmail.com', 'identifier_type': 'email'}, {'role': 'recipient', 'metadata': {}, 'identifier': '+17742531317', 'identifier_type': 'phone'}]\n",
            "Sender: {'role': 'sender', 'metadata': {}, 'identifier': 'E:mrwhistler@gmail.com', 'identifier_type': 'email'}\n",
            "\n",
            "âš  No thread context found (document may be first in thread)\n",
            "\n",
            "================================================================================\n",
            "RUNNING INTENT PIPELINE\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "INTENT CLASSIFICATION PROMPT (sent to Ollama)\n",
            "================================================================================\n",
            "You are an intent classification assistant. Given the following artifact text, extracted entities, and optional conversation context, identify which intents from the provided taxonomy are present.\n",
            "\n",
            "Return a JSON object with this structure:\n",
            "{\n",
            "  \"intents\": [\n",
            "    {\"name\": \"<intent_name>\", \"base_confidence\": 0.0-1.0, \"reasons\": [\"detailed explanation\"]}\n",
            "  ],\n",
            "  \"notes\": [\"optional explanatory notes\"]\n",
            "}\n",
            "\n",
            "Guidelines:\n",
            "- Only include intents whose confidence is at least 0.35.\n",
            "- Confidence values must be floats between 0 and 1.\n",
            "- Use multi-label classification (zero or more intents may apply).\n",
            "- For each intent, provide detailed reasons explaining WHY it matches:\n",
            "  * Quote specific phrases from the text that indicate this intent\n",
            "  * Explain semantic patterns (e.g., 'remember to' suggests reminder.create)\n",
            "  * Note any contextual clues from channel metadata or conversation history\n",
            "  * Do NOT just list slot names - explain the reasoning\n",
            "- Consider conversation context when resolving ambiguous references.\n",
            "\n",
            "Taxonomy version: 1.0.0\n",
            "Available intents:\n",
            "- task.create: Create a new task or to-do item that the user wants to track. Slots: what (string, required), due_date (datetime, optional), assignee (person, optional), source_ref (string, required).\n",
            "- schedule.create: Schedule a calendar event, meeting, appointment, block, or anything else that needs to be added to the calendar. Slots: start_dt (datetime, required), end_dt (datetime, optional), location (location, optional), participants (array[person], optional), title (string, optional), source_ref (string, required).\n",
            "- reminder.create: Create a reminder or follow-up notification for the user. Slots: what (string, required), remind_at (datetime, optional), person (person, optional), source_ref (string, required).\n",
            "\n",
            "Entities (JSON):\n",
            "{}\n",
            "\n",
            "Current artifact text:\n",
            "-----\n",
            "From Chris Patten: Hey if u think of it could you grab me a couple more of those tank things?\n",
            "-----\n",
            "================================================================================\n",
            "\n",
            "HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
            "\n",
            "================================================================================\n",
            "SLOT EXTRACTION PROMPT (sent to Ollama) - Intent: task.create\n",
            "Missing slots: ['what', 'due_date', 'assignee']\n",
            "================================================================================\n",
            "You are an assistant that extracts missing slot values for intents.\n",
            "Intent: task.create\n",
            "Intent description: Create a new task or to-do item that the user wants to track.\n",
            "\n",
            "Missing slot definitions:\n",
            "- \"what\" (string, required) (The action or task to be completed. Extract the complete verb phrase describing what needs to be done (e.g., 'pick up eggs', 'call the dentist', 'review the proposal'). Include the full action, not just the object.).\n",
            "- \"due_date\" (datetime, optional) (Due date or deadline for the task.). Constraints: {\"min\": \"now\"}.\n",
            "- \"assignee\" (person, optional) (Person responsible for completing the task.).\n",
            "\n",
            "Extraction rules:\n",
            "- Return strict JSON with keys: slots (object) and notes (array of strings).\n",
            "- Only include the slots requested. Do not include already known slots unless a better value is available.\n",
            "- Extract values from the artifact text, entities, or conversation context.\n",
            "- For datetime slots, return ISO 8601 strings with timezone offsets (e.g., 2025-11-09T15:04:00-05:00). If timezone unknown, assume UTC and append 'Z'.\n",
            "- For time ranges, parse common formats: '12 to 1230' = 12:00 PM to 12:30 PM, '9-10' = 9:00 AM to 10:00 AM, '2pm to 3pm' = 14:00 to 15:00. When both start_dt and end_dt are needed, extract both from the range.\n",
            "- For person slots, return objects with at least a 'name' property. Include 'role' (e.g., 'sender', 'recipient', 'assignee') and 'identifier' if available from entities or channel context.\n",
            "- For array[person] slots, return a list of person objects as described above.\n",
            "- For location slots, prefer structured references from entities; otherwise, extract from the artifact text.\n",
            "- For string slots, preserve the full semantic meaning (e.g., 'pick up eggs for me' not just 'eggs').\n",
            "\n",
            "IMPORTANT: For the 'what' slot, extract the complete action or task being requested. Look for verb phrases that describe what needs to be done (e.g., 'pick up eggs', 'call the dentist', 'review the proposal'). Include the full action phrase, not just the object. If the text says 'pick up eggs', extract 'pick up eggs' (not just 'eggs').\n",
            "- Do not hallucinate values. If information is unavailable, omit the slot and explain in notes.\n",
            "\n",
            "Existing slots (already filled):\n",
            "{\n",
            "  \"source_ref\": \"12c4133d-991d-4afb-8dcc-5076973c0110\"\n",
            "}\n",
            "\n",
            "Entities (pre-extracted):\n",
            "{}\n",
            "\n",
            "Classifier notes: [\"Task creation intent is more likely due to the mention of 'track something' and 'grab me some', which suggests a task creation request.\"]\n",
            "\n",
            "Document timestamp (when message was sent/received): 2025-09-16T02:08:05+00:00\n",
            "\n",
            "Current artifact text:\n",
            "-----\n",
            "From Chris Patten: Hey if u think of it could you grab me a couple more of those tank things?\n",
            "-----\n",
            "\n",
            "================================================================================\n",
            "\n",
            "HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
            "\n",
            "================================================================================\n",
            "SLOT EXTRACTION PROMPT (sent to Ollama) - Intent: reminder.create\n",
            "Missing slots: ['what', 'remind_at', 'person']\n",
            "================================================================================\n",
            "You are an assistant that extracts missing slot values for intents.\n",
            "Intent: reminder.create\n",
            "Intent description: Create a reminder or follow-up notification for the user.\n",
            "\n",
            "Missing slot definitions:\n",
            "- \"what\" (string, required) (The action or task to be reminded about. Extract the complete verb phrase describing what needs to be done (e.g., 'pick up eggs', 'call the dentist', 'review the proposal'). Include the full action, not just the object.).\n",
            "- \"remind_at\" (datetime, optional) (When the reminder should trigger.).\n",
            "- \"person\" (person, optional) (Optional person the reminder is about.).\n",
            "\n",
            "Extraction rules:\n",
            "- Return strict JSON with keys: slots (object) and notes (array of strings).\n",
            "- Only include the slots requested. Do not include already known slots unless a better value is available.\n",
            "- Extract values from the artifact text, entities, or conversation context.\n",
            "- For datetime slots, return ISO 8601 strings with timezone offsets (e.g., 2025-11-09T15:04:00-05:00). If timezone unknown, assume UTC and append 'Z'.\n",
            "- For time ranges, parse common formats: '12 to 1230' = 12:00 PM to 12:30 PM, '9-10' = 9:00 AM to 10:00 AM, '2pm to 3pm' = 14:00 to 15:00. When both start_dt and end_dt are needed, extract both from the range.\n",
            "- For person slots, return objects with at least a 'name' property. Include 'role' (e.g., 'sender', 'recipient', 'assignee') and 'identifier' if available from entities or channel context.\n",
            "- For array[person] slots, return a list of person objects as described above.\n",
            "- For location slots, prefer structured references from entities; otherwise, extract from the artifact text.\n",
            "- For string slots, preserve the full semantic meaning (e.g., 'pick up eggs for me' not just 'eggs').\n",
            "\n",
            "IMPORTANT: For the 'what' slot, extract the complete action or task being requested. Look for verb phrases that describe what needs to be done (e.g., 'pick up eggs', 'call the dentist', 'review the proposal'). Include the full action phrase, not just the object. If the text says 'pick up eggs', extract 'pick up eggs' (not just 'eggs').\n",
            "- Do not hallucinate values. If information is unavailable, omit the slot and explain in notes.\n",
            "\n",
            "Existing slots (already filled):\n",
            "{\n",
            "  \"source_ref\": \"12c4133d-991d-4afb-8dcc-5076973c0110\"\n",
            "}\n",
            "\n",
            "Entities (pre-extracted):\n",
            "{}\n",
            "\n",
            "Classifier notes: [\"Task creation intent is more likely due to the mention of 'track something' and 'grab me some', which suggests a task creation request.\"]\n",
            "\n",
            "Document timestamp (when message was sent/received): 2025-09-16T02:08:05+00:00\n",
            "\n",
            "Current artifact text:\n",
            "-----\n",
            "From Chris Patten: Hey if u think of it could you grab me a couple more of those tank things?\n",
            "-----\n",
            "\n",
            "================================================================================\n",
            "\n",
            "HTTP Request: POST http://localhost:11434/api/generate \"HTTP/1.1 200 OK\"\n",
            "\n",
            "================================================================================\n",
            "SLOT EXTRACTION DEBUG INFO\n",
            "================================================================================\n",
            "Intent: task.create\n",
            "Filled slots: ['source_ref', 'what']\n",
            "Missing required slots: []\n",
            "Missing optional slots: ['due_date', 'assignee']\n",
            "================================================================================\n",
            "\n",
            "Slots that SHOULD be extracted: ['due_date', 'assignee']\n",
            "  Required missing: []\n",
            "  Optional missing: ['due_date', 'assignee']\n",
            "CLASSIFIER OUTPUT\n",
            "================================================================================\n",
            "\n",
            "âœ“ Intent: task.create\n",
            "  Confidence: 72.00% (base: 72.00%, prior: 1.00x)\n",
            "  Reasons:\n",
            "    â€¢ u want to track something\n",
            "    â€¢ grab me some\n",
            "\n",
            "âœ“ Intent: reminder.create\n",
            "  Confidence: 41.00% (base: 41.00%, prior: 1.00x)\n",
            "  Reasons:\n",
            "    â€¢ follow-up notification for the user\n",
            "\n",
            "================================================================================\n",
            "SLOT FILLING OUTPUT\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‹ Intent: task.create (72.00%)\n",
            "  âœ“ Resolved Slots:\n",
            "    â€¢ source_ref (from default): 12c4133d-991d-4afb-8dcc-5076973c0110\n",
            "    â€¢ what (from llm): grab some tank things\n",
            "  â„¹ Notes:\n",
            "    â€¢ No due date provided in the message.\n",
            "    â€¢ Person 'Chris Patten' assigned to task, but no role specified. Could be sender or recipient.\n",
            "    â€¢ Location not specified, assuming a general reference.\n",
            "\n",
            "ðŸ“‹ Intent: reminder.create (41.00%)\n",
            "  âœ“ Resolved Slots:\n",
            "    â€¢ source_ref (from default): 12c4133d-991d-4afb-8dcc-5076973c0110\n",
            "    â€¢ what (from llm): grab me a couple more of those tank things\n",
            "  â„¹ Notes:\n",
            "    â€¢ Missing 'remind_at' and 'person' slots. Information available for 'what' slot from artifact text.\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Document ID: 12c4133d-991d-4afb-8dcc-5076973c0110\n",
            "External ID: imessage:4C99B3B9-BA1D-4537-92DB-C59D22A0E3A6\n",
            "Source type: imessage\n",
            "Thread ID: 4c14bb3a-45ee-4f86-ba53-162549a97265\n",
            "Thread context messages: 0\n",
            "Text analyzed: 'Hey if u think of it could you grab me a couple more of thos...'\n",
            "Intents detected: 2\n",
            "Top intent: task.create\n",
            "Resolved slots: 2 / 2\n",
            "\n",
            "================================================================================\n",
            "FINAL INTENT OUTPUT (for database storage)\n",
            "================================================================================\n",
            "\n",
            "Intent JSONB payload (documents.intent column):\n",
            "{\n",
            "  \"taxonomy_version\": \"1.0.0\",\n",
            "  \"classification\": {\n",
            "    \"intents\": [\n",
            "      {\n",
            "        \"intent_name\": \"task.create\",\n",
            "        \"confidence\": 0.72,\n",
            "        \"base_confidence\": 0.72,\n",
            "        \"prior_applied\": 1.0,\n",
            "        \"reasons\": [\n",
            "          \"u want to track something\",\n",
            "          \"grab me some\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"intent_name\": \"reminder.create\",\n",
            "        \"confidence\": 0.41,\n",
            "        \"base_confidence\": 0.41,\n",
            "        \"prior_applied\": 1.0,\n",
            "        \"reasons\": [\n",
            "          \"follow-up notification for the user\"\n",
            "        ]\n",
            "      }\n",
            "    ],\n",
            "    \"processing_notes\": [\n",
            "      \"Task creation intent is more likely due to the mention of 'track something' and 'grab me some', which suggests a task creation request.\"\n",
            "    ]\n",
            "  },\n",
            "  \"slot_assignments\": [\n",
            "    {\n",
            "      \"intent_name\": \"task.create\",\n",
            "      \"confidence\": 0.72,\n",
            "      \"slots\": {\n",
            "        \"source_ref\": \"12c4133d-991d-4afb-8dcc-5076973c0110\",\n",
            "        \"what\": \"grab some tank things\"\n",
            "      },\n",
            "      \"missing_slots\": [],\n",
            "      \"slot_sources\": {\n",
            "        \"source_ref\": \"default\",\n",
            "        \"what\": \"llm\"\n",
            "      },\n",
            "      \"notes\": [\n",
            "        \"No due date provided in the message.\",\n",
            "        \"Person 'Chris Patten' assigned to task, but no role specified. Could be sender or recipient.\",\n",
            "        \"Location not specified, assuming a general reference.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"intent_name\": \"reminder.create\",\n",
            "      \"confidence\": 0.41,\n",
            "      \"slots\": {\n",
            "        \"source_ref\": \"12c4133d-991d-4afb-8dcc-5076973c0110\",\n",
            "        \"what\": \"grab me a couple more of those tank things\"\n",
            "      },\n",
            "      \"missing_slots\": [],\n",
            "      \"slot_sources\": {\n",
            "        \"source_ref\": \"default\",\n",
            "        \"what\": \"llm\"\n",
            "      },\n",
            "      \"notes\": [\n",
            "        \"Missing 'remind_at' and 'person' slots. Information available for 'what' slot from artifact text.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"slot_filling_notes\": [\n",
            "    \"No due date provided in the message.\",\n",
            "    \"Person 'Chris Patten' assigned to task, but no role specified. Could be sender or recipient.\",\n",
            "    \"Location not specified, assuming a general reference.\",\n",
            "    \"Missing 'remind_at' and 'person' slots. Information available for 'what' slot from artifact text.\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Set the document_id to process\n",
        "document_id = DOCUMENT_ID  # Replace with actual UUID\n",
        "\n",
        "# Fetch the document\n",
        "doc = fetch_document_by_id(document_id)\n",
        "if not doc:\n",
        "    print(f\"Document not found: {document_id}\")\n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"PROCESSING DOCUMENT: {doc.doc_id}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"External ID: {doc.external_id}\")\n",
        "    print(f\"Source Type: {doc.source_type}\")\n",
        "    print(f\"Thread ID: {doc.thread_id}\")\n",
        "    print(f\"Text preview: {doc.text[:200]}...\")\n",
        "    \n",
        "    # Extract entities from document metadata\n",
        "    doc_entities = {}\n",
        "    \n",
        "    # Extract channel context from metadata\n",
        "    metadata = doc.metadata or {}\n",
        "    channel_meta = metadata.get(\"channel\") or {}\n",
        "    if channel_meta:\n",
        "        doc_entities[\"channel_context\"] = {\n",
        "            \"from\": channel_meta.get(\"from\") or channel_meta.get(\"sender\"),\n",
        "            \"to\": channel_meta.get(\"to\") or [],\n",
        "        }\n",
        "            \n",
        "    \n",
        "    # Extract dates/entities from metadata if available\n",
        "    if \"dates\" in metadata:\n",
        "        doc_entities[\"dates\"] = metadata[\"dates\"]\n",
        "    if \"places\" in metadata:\n",
        "        doc_entities[\"places\"] = metadata[\"places\"]\n",
        "\n",
        "    sender_name = get_sender_name(doc)\n",
        "    if sender_name:\n",
        "        doc_text = f\"From {sender_name}: {doc.text}\"\n",
        "    else:\n",
        "        doc_text = doc.text\n",
        "    \n",
        "    # Fetch thread context if available\n",
        "    thread_context = None\n",
        "    if doc.thread_id:\n",
        "        thread_context = fetch_thread_context(doc.doc_id, limit=10)\n",
        "        if thread_context:\n",
        "            print(f\"\\nâœ“ Found {len(thread_context)} previous messages in thread\")\n",
        "            print(\"Thread context preview:\")\n",
        "            for i, msg in enumerate(thread_context[-3:], 1):  # Show last 3\n",
        "                sender = msg.get(\"sender\", \"unknown\")\n",
        "                text_preview = msg.get(\"text\", \"\")[:100]\n",
        "                print(f\"  {i}. [{sender}]: {text_preview}...\")\n",
        "        else:\n",
        "            print(\"\\nâš  No thread context found (document may be first in thread)\")\n",
        "    \n",
        "    # Run the intent pipeline with thread context\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RUNNING INTENT PIPELINE\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Format content_timestamp for passing to slot filler\n",
        "    content_timestamp_str = None\n",
        "    if doc.content_timestamp:\n",
        "        if isinstance(doc.content_timestamp, str):\n",
        "            content_timestamp_str = doc.content_timestamp\n",
        "        else:\n",
        "            # Convert datetime to ISO string\n",
        "            content_timestamp_str = doc.content_timestamp.isoformat()\n",
        "    \n",
        "    classification, slot_result = run_intent_pipeline(\n",
        "        text=doc_text,\n",
        "        entities=doc_entities,\n",
        "        source_type=doc.source_type,\n",
        "        artifact_id=str(doc.doc_id),\n",
        "        thread_context=thread_context,\n",
        "        content_timestamp=content_timestamp_str,\n",
        "    )\n",
        "    \n",
        "    # Show detailed slot extraction debugging for the first intent (if there are missing slots)\n",
        "    if classification.intents and slot_result.assignments:\n",
        "        taxonomy = load_intent_taxonomy()\n",
        "        top_intent = classification.intents[0]\n",
        "        top_assignment = slot_result.assignments[0]\n",
        "        intent_def = taxonomy.intents.get(top_intent.intent_name)\n",
        "        \n",
        "        # Debug: Show what slots were requested for extraction\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"SLOT EXTRACTION DEBUG INFO\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Intent: {top_intent.intent_name}\")\n",
        "        print(f\"Filled slots: {list(top_assignment.slots.keys())}\")\n",
        "        print(f\"Missing required slots: {top_assignment.missing_slots}\")\n",
        "        if intent_def:\n",
        "            all_optional = [name for name, defn in intent_def.slots.items() if not defn.required]\n",
        "            missing_optional = [name for name in all_optional if name not in top_assignment.slots]\n",
        "            print(f\"Missing optional slots: {missing_optional}\")\n",
        "            if top_intent.intent_name == \"schedule.create\":\n",
        "                print(f\"Title slot exists in taxonomy: {'title' in intent_def.slots}\")\n",
        "                print(f\"Title slot filled: {'title' in top_assignment.slots}\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        # Show what slots should be extracted (including optional ones like title)\n",
        "        if intent_def:\n",
        "            all_missing = top_assignment.missing_slots.copy()\n",
        "            # Add optional slots that aren't filled\n",
        "            for slot_name, slot_def in intent_def.slots.items():\n",
        "                if not slot_def.required and slot_name not in top_assignment.slots:\n",
        "                    if slot_name not in all_missing:\n",
        "                        all_missing.append(slot_name)\n",
        "            # For schedule.create, ensure title is included\n",
        "            if top_intent.intent_name == \"schedule.create\" and \"title\" not in top_assignment.slots:\n",
        "                if \"title\" not in all_missing:\n",
        "                    all_missing.append(\"title\")\n",
        "            \n",
        "            print(f\"\\nSlots that SHOULD be extracted: {all_missing}\")\n",
        "            print(f\"  Required missing: {top_assignment.missing_slots}\")\n",
        "            print(f\"  Optional missing: {[s for s in all_missing if s not in top_assignment.missing_slots]}\")\n",
        "        \n",
        "        if intent_def and top_assignment.missing_slots:\n",
        "            slot_filler = build_slot_filler()\n",
        "            extractor = slot_filler._extractor\n",
        "            \n",
        "            # Build the prompt that would be used for missing slots (including optional ones)\n",
        "            # Reconstruct what the extraction targets should be\n",
        "            extraction_targets = top_assignment.missing_slots.copy()\n",
        "            for slot_name, slot_def in intent_def.slots.items():\n",
        "                if not slot_def.required and slot_name not in top_assignment.slots:\n",
        "                    if slot_name not in extraction_targets:\n",
        "                        extraction_targets.append(slot_name)\n",
        "            # For schedule.create, ensure title is prioritized\n",
        "            if top_intent.intent_name == \"schedule.create\" and \"title\" not in top_assignment.slots:\n",
        "                if \"title\" in extraction_targets:\n",
        "                    extraction_targets.remove(\"title\")\n",
        "                    extraction_targets.insert(len(top_assignment.missing_slots), \"title\")  # Insert after required slots\n",
        "                elif \"title\" in intent_def.slots:\n",
        "                    extraction_targets.insert(len(top_assignment.missing_slots), \"title\")\n",
        "            \n",
        "            print(f\"\\nBuilding prompt for extraction targets: {extraction_targets}\")\n",
        "            \n",
        "            # Build the prompt that would be used for missing slots\n",
        "            prompt = extractor._build_prompt(\n",
        "                intent_name=top_intent.intent_name,\n",
        "                intent_definition=intent_def,\n",
        "                text=doc.text,\n",
        "                entities=doc_entities,\n",
        "                existing_slots=top_assignment.slots,\n",
        "                missing_slots=extraction_targets,  # Use the full list including optional slots\n",
        "                classification_notes=classification.processing_notes or [],\n",
        "                thread_context=thread_context,\n",
        "                content_timestamp=content_timestamp_str,\n",
        "            )\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(\"SLOT EXTRACTION DEBUGGING (for missing slots)\")\n",
        "            print(\"=\" * 80)\n",
        "            print(\"\\nPrompt sent to LLM:\")\n",
        "            print(\"-\" * 80)\n",
        "            print(prompt[:2000] + \"...\" if len(prompt) > 2000 else prompt)\n",
        "            \n",
        "            print(\"\\n\" + \"-\" * 80)\n",
        "            print(\"RAW OLLAMA SLOT EXTRACTION RESPONSE\")\n",
        "            print(\"-\" * 80)\n",
        "            payload = {\n",
        "                \"model\": INTENT_MODEL,\n",
        "                \"prompt\": prompt,\n",
        "                \"format\": \"json\",\n",
        "                \"stream\": False,\n",
        "            }\n",
        "            raw_response = extractor._invoke_ollama(payload)\n",
        "            print(raw_response)\n",
        "            \n",
        "            print(\"\\n\" + \"-\" * 80)\n",
        "            print(\"PARSED SLOT EXTRACTION JSON\")\n",
        "            print(\"-\" * 80)\n",
        "            parsed = extractor._parse_response(raw_response)\n",
        "            print(json.dumps(parsed, indent=2))\n",
        "            \n",
        "            if \"slots\" in parsed:\n",
        "                print(\"\\n\" + \"-\" * 80)\n",
        "                print(\"EXTRACTED SLOTS FROM LLM\")\n",
        "                print(\"-\" * 80)\n",
        "                print(json.dumps(parsed[\"slots\"], indent=2))\n",
        "                for slot_name in top_assignment.missing_slots:\n",
        "                    if slot_name in parsed[\"slots\"]:\n",
        "                        print(f\"\\nâœ“ '{slot_name}' slot found: {repr(parsed['slots'][slot_name])}\")\n",
        "                    else:\n",
        "                        print(f\"\\nâœ— '{slot_name}' slot NOT found in response\")\n",
        "            \n",
        "            if \"notes\" in parsed:\n",
        "                print(\"\\n\" + \"-\" * 80)\n",
        "                print(\"EXTRACTION NOTES FROM LLM\")\n",
        "                print(\"-\" * 80)\n",
        "                for note in parsed[\"notes\"]:\n",
        "                    print(f\"  â€¢ {note}\")\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "    \n",
        "    # Show formatted classifier and slot filling output\n",
        "    print(\"CLASSIFIER OUTPUT\")\n",
        "    print(\"=\" * 80)\n",
        "    for intent in classification.intents:\n",
        "        print(f\"\\nâœ“ Intent: {intent.intent_name}\")\n",
        "        print(f\"  Confidence: {intent.confidence:.2%} (base: {intent.base_confidence:.2%}, prior: {intent.prior_applied:.2f}x)\")\n",
        "        if intent.reasons:\n",
        "            print(f\"  Reasons:\")\n",
        "            for reason in intent.reasons:\n",
        "                print(f\"    â€¢ {reason}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SLOT FILLING OUTPUT\")\n",
        "    print(\"=\" * 80)\n",
        "    for assignment in slot_result.assignments:\n",
        "        print(f\"\\nðŸ“‹ Intent: {assignment.intent_name} ({assignment.confidence:.2%})\")\n",
        "        \n",
        "        if assignment.slots:\n",
        "            print(f\"  âœ“ Resolved Slots:\")\n",
        "            for slot_name, value in assignment.slots.items():\n",
        "                source = assignment.slot_sources.get(slot_name, \"?\")\n",
        "                if isinstance(value, (dict, list)):\n",
        "                    print(f\"    â€¢ {slot_name} (from {source}): {json.dumps(value)}\")\n",
        "                else:\n",
        "                    print(f\"    â€¢ {slot_name} (from {source}): {value}\")\n",
        "        \n",
        "        if assignment.missing_slots:\n",
        "            print(f\"  âš  Missing Required Slots: {', '.join(assignment.missing_slots)}\")\n",
        "        \n",
        "        if assignment.notes:\n",
        "            print(f\"  â„¹ Notes:\")\n",
        "            for note in assignment.notes:\n",
        "                print(f\"    â€¢ {note}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Document ID: {doc.doc_id}\")\n",
        "    print(f\"External ID: {doc.external_id}\")\n",
        "    print(f\"Source type: {doc.source_type}\")\n",
        "    print(f\"Thread ID: {doc.thread_id}\")\n",
        "    print(f\"Thread context messages: {len(thread_context) if thread_context else 0}\")\n",
        "    print(f\"Text analyzed: '{doc.text[:60]}...'\")\n",
        "    print(f\"Intents detected: {len(classification.intents)}\")\n",
        "    print(f\"Top intent: {classification.intents[0].intent_name if classification.intents else 'none'}\")\n",
        "    if slot_result.assignments:\n",
        "        top_assignment = slot_result.assignments[0]\n",
        "        print(f\"Resolved slots: {len(top_assignment.slots)} / {len(top_assignment.slots) + len(top_assignment.missing_slots)}\")\n",
        "    \n",
        "    # Show the final intent output that will be stored in the database\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"FINAL INTENT OUTPUT (for database storage)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Build the intent JSONB structure that matches what will be stored\n",
        "    intent_payload = {\n",
        "        \"taxonomy_version\": classification.taxonomy_version,\n",
        "        \"classification\": {\n",
        "            \"intents\": [\n",
        "                {\n",
        "                    \"intent_name\": intent.intent_name,\n",
        "                    \"confidence\": intent.confidence,\n",
        "                    \"base_confidence\": intent.base_confidence,\n",
        "                    \"prior_applied\": intent.prior_applied,\n",
        "                    \"reasons\": intent.reasons,\n",
        "                }\n",
        "                for intent in classification.intents\n",
        "            ],\n",
        "            \"processing_notes\": classification.processing_notes or [],\n",
        "        },\n",
        "        \"slot_assignments\": [\n",
        "            {\n",
        "                \"intent_name\": assignment.intent_name,\n",
        "                \"confidence\": assignment.confidence,\n",
        "                \"slots\": assignment.slots,\n",
        "                \"missing_slots\": assignment.missing_slots,\n",
        "                \"slot_sources\": assignment.slot_sources,\n",
        "                \"notes\": assignment.notes,\n",
        "            }\n",
        "            for assignment in slot_result.assignments\n",
        "        ],\n",
        "        \"slot_filling_notes\": slot_result.notes or [],\n",
        "    }\n",
        "    \n",
        "    print(\"\\nIntent JSONB payload (documents.intent column):\")\n",
        "    print(json.dumps(intent_payload, indent=2, default=str))\n",
        "   \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
